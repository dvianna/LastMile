{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e663ae",
   "metadata": {},
   "source": [
    "## 2021 Amazon Last Mile Routing Research Challenge\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "    aws s3 --no-sign-request cp s3://amazon-last-mile-challenges/almrrc2021/ ./data --recursive\n",
    "\n",
    "Training data: /data/almrrc2021-data-training  \\\n",
    "Test data: /data/almrrc2021-data-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d63178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in /home/dvianna/anaconda3/lib/python3.9/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.14 in /home/dvianna/anaconda3/lib/python3.9/site-packages (from shapely) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "edc52746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m410.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /home/dvianna/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/dvianna/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dvianna/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/dvianna/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff6bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import datetime as dt\n",
    "import statistics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2248e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as fp:\n",
    "            json_data = json.loads(fp.read())\n",
    "        fp.close() \n",
    "        return json_data\n",
    "    except FileNotFoundError:\n",
    "        print(\"Missing file: %s\", filepath)\n",
    "    except Exception as e:\n",
    "        print(\"Error trying to read file %s: %s\", (pathfile, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753a5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area(points):\n",
    "    polygon = Polygon(points)\n",
    "    # the area in square degrees\n",
    "    area = polygon.area\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adeeee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_between(time, time_range):\n",
    "    if time_range[1] < time_range[0]:\n",
    "        return time >= time_range[0] or time <= time_range[1]\n",
    "    return time_range[0] <= time <= time_range[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30523fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_in_between(rush_hour, start_route, end_route):\n",
    "    if (start_route < rush_hour[1] and end_route > rush_hour[0]) or (start_route > rush_hour[1] and end_route > rush_hour[0] and end_route < start_route) or (start_route < rush_hour[1] and (end_route < start_route)) or (rush_hour[0] < start_route < rush_hour[1]) or (rush_hour[0] < end_route < rush_hour[1]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acba277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(value):\n",
    "    try:\n",
    "        import math\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd5c2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Train/test features\n",
    "    Adding new fetures to the original feature set\n",
    "\"\"\"\n",
    "def create_features(phase=\"build\", features_file='./new_features.json'):\n",
    "    # feature vector and labels\n",
    "    all_features = []\n",
    "\n",
    "    weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    times_of_the_day = [\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\",\n",
    "                        \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
    "\n",
    "    # stat_weekday_low = [0, 0, 0, 0, 0, 0, 0]\n",
    "    # stat_weekday_high = [0, 0, 0, 0, 0, 0, 0]\n",
    "    # stat_weekday_medium = [0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    hour_low = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    hour_medium = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    hour_high = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Features:\n",
    "    routeID: route id\n",
    "    route_size: route size (number of stops per route)\n",
    "    total_delivery_time: route total time (distance + time for package delivery)\n",
    "    travel_time: time to travel between stops (distance)\n",
    "    violation_count: window violation count\n",
    "    violation_avg_time: window violation average time (seconds)\n",
    "    violation_total_time: window violation total time (seconds)\n",
    "    ratio_violation_w_total_time: ratio between window violation time and window total time        \n",
    "    violation_early_total_time: window violation total time - arrived early (time in seconds)\n",
    "    violation_late_total_time: window violation total time - arrived late (time in seconds)\n",
    "    violation_early_avg_time: window violation avg time - arrived early (time in seconds)\n",
    "    violation_late_avg_time: window violation avg time - arrived late (time in seconds)\n",
    "    violation_early_count:  window violation count - arrived early\n",
    "    violation_late_count: window violation time - arrived late\n",
    "    ratio_early_violation: ratio between window violation time and window total time - arrived early\n",
    "    ratio_late_violation: ratio between window violation time and window total time - arrived late       \n",
    "    zones_count: number of unique zones per route\n",
    "    backtracking_count: backtracking count (number of times a driver leaves and then goes back to a zone) \n",
    "    ratio_backtracking_route_size: ratio between backtracking count and route size\n",
    "    ratio_backtracking_route_zones: ratio between backtracking count and number of unique zones in a route\n",
    "\n",
    "    ratio_delivery_time_stops: ratio between delivery time and number of stops\n",
    "    ratio_zones_delivery_time: ratio between number of unique zones and delivery time \n",
    "    ratio_route_size_delivery_time: ratio between route size (number of stops) and delivery time\n",
    "    ratio_packages_count_delivery_time: ratio between number of packages and delivery time\n",
    "    ratio_violation_delivery_time: ratio between window violation count and delivery time (route size)\n",
    "    ratio_delivery_time_stops: ratio between delivery time and number of stops (route size)\n",
    "    ratio_delivery_time_packages_count: ratio between delivery time and number of packages\n",
    "\n",
    "    ratio_travel_time_stops: ratio between travel time and number of stops        \n",
    "    ratio_zones_route_size: ratio between number of unique zones and route size (number of stops per route)\n",
    "    ratio_zones_travel_time: ratio between number of unique zones and travel time \n",
    "    ratio_route_size_travel_time: ratio between route size (number of stops) and travel time\n",
    "    ratio_packages_count_travel_time: ratio between number of packages and travel time\n",
    "    ratio_packages_count_route_size: ratio between number of packages and route size (number of stops per route)\n",
    "    ratio_violation_travel_time: ratio between window violation count and travel time (route size)\n",
    "    ratio_travel_time_stops: ratio between travel time and number of stops (route size)\n",
    "    ratio_travel_time_packages_count: ratio between travel time and number of packages\n",
    "    ratio_package_count_violation_avg_time: ratio between packages count and window violation total time\n",
    "    ratio_package_count_violation_total_time: ratio between packages count (not delivered on time) and window \n",
    "    violation total time\n",
    "    ratio_package_count_violation_late_avg_time: ratio between avg packages count (delivered late) and window \n",
    "    violation (late) average time\n",
    "    ratio_package_count_violation_late_total_time: ration between total packages count (delivered late) and window \n",
    "    violation (late) total time\n",
    "    ratio_package_volume_delivery_time: ratio between packages volume and delivery time\n",
    "    ratio_package_volume_violation_time: ratio between packages volume (not delivered on time) and window violation \n",
    "    total time\n",
    "    ratio_package_volume_violation_late_total_time: ratio between packages (not delivered on time) volume and window \n",
    "    violation (late) total time      \n",
    "    rush_hour_morning (7am-9am): route went through morning rush hour\n",
    "    rush_hour_evening (5pm-7pm): route went through evening rush hour  \n",
    "    time of the day: hour_00, hour_01, hour_02, hour_03 ... hour_24\n",
    "    Day of the week: monday, tuesday, wednesday, thursday, friday, saturday, sunday\n",
    "    area: area of polygon using all (lat, lng) in one route \n",
    "\n",
    "    ratio_backtracking_travel_time: ration between backtracking count and travel time\n",
    "    ratio_backtracking_delivery_time: ration between backtracking count and travel time\n",
    "\n",
    "    # time between stops - statistics\n",
    "    min_time_btw_stops\n",
    "    max_time_btw_stops\n",
    "    std_time_btw_stops\n",
    "    median_time_btw_stops\n",
    "    mean_time_btw_stops\n",
    "\n",
    "    # packages per stop - statistics\n",
    "    min_packages_per_stop \n",
    "    max_packages_per_stop\n",
    "    std_packages_per_stop\n",
    "    median_packages_per_stop\n",
    "    mean_packages_per_stop\n",
    "\n",
    "    # planned service time statistics\n",
    "    min_planned_service_time\n",
    "    max_planned_service_time\n",
    "    std_planned_service_time\n",
    "    median_planned_service_time\n",
    "    mean_planned_service_time\n",
    "\n",
    "    ratio_packages_planned_service: ratio between packages count and planned service time\n",
    "    ratio_package_volume_planned_service: ratio between package volume and planned service time\n",
    "    total_planned_service_time: total planned service time\n",
    "\n",
    "\n",
    "    MISSING:\n",
    "    distance: distance (km)\n",
    "    ratio_distance_travel_time: ratio between distance and total travel time\n",
    "    ratio_distance_route_size: ratio between distance and number of stops (average distance)\n",
    "    ratio between avg distance between two stops and time window violation\n",
    "\n",
    "    # Number of time the planned service time is greater than travel time between stops\n",
    "\n",
    "    MAYBE:        \n",
    "    One feature per zone - help to identify difficult routes\n",
    "    Numero de vezes em que o planned service time 'e maior que o tempo de viagem entre os stops (e a razao)\n",
    "\n",
    "    \"\"\"\n",
    "    # For each route, compute new features\n",
    "    for routeID in route_data.keys():\n",
    "        # create feature dictionary for each route\n",
    "        features = {'routeID': routeID}\n",
    "        # get route data\n",
    "        route = route_data[routeID]\n",
    "        route_date = route['date_YYYY_MM_DD']\n",
    "        route_departure_time = route['departure_time_utc']\n",
    "        # route_size: route size (number of stops per route)\n",
    "        route_size = len(route[\"stops\"].keys())\n",
    "        features['route_size'] = route_size\n",
    "\n",
    "        # combine attributes date_YYYY_MM_DD with departure_time_utc\n",
    "        date = dt.datetime.strptime(route['date_YYYY_MM_DD'], '%Y-%m-%d')\n",
    "        time = dt.datetime.strptime(route['departure_time_utc'], '%H:%M:%S').time()\n",
    "        start_time = dt.datetime.combine(date, time)\n",
    "\n",
    "        lat_lng = []\n",
    "\n",
    "        # indicative variable for weekday\n",
    "        for item in weekdays:\n",
    "            if item == weekdays[date.weekday()]:\n",
    "                features[item] = 1\n",
    "            else:\n",
    "                features[item] = 0\n",
    "\n",
    "        # get actual sequence\n",
    "        if phase == 'build':\n",
    "            sequence = actual_sequences_data[routeID]['actual']\n",
    "        else:  # phase = 'apply'\n",
    "            sequence = actual_sequences_data[routeID]['proposed']\n",
    "        sequence = sorted(sequence, key=sequence.get)\n",
    "        # travel and delivery time variables\n",
    "        travel_time = 0\n",
    "        delivery_time = 0\n",
    "        total_delivery_time = 0\n",
    "        # time window for package delivery\n",
    "        tw_violated = 0\n",
    "        tw_violated_early = 0\n",
    "        tw_violated_late = 0\n",
    "        # time window difference when violated (total per route)\n",
    "        difference = 0\n",
    "        difference_early = 0\n",
    "        difference_late = 0\n",
    "        # time window for all stops (total em seconds)\n",
    "        tw_total = 0\n",
    "        # zones sequence\n",
    "        zones = []\n",
    "        backtracking = 0\n",
    "        unique_zones = 0\n",
    "        # packages count\n",
    "        package_count = 0\n",
    "        package_count_violation = 0\n",
    "        package_count_total_violation = 0\n",
    "        package_count_late_violation = 0\n",
    "        # packages volume\n",
    "        package_volume = 0\n",
    "        package_volume_late_violation = 0\n",
    "        # time between stops\n",
    "        time_between_stops = []\n",
    "        # packages per stop\n",
    "        packages_stat_per_stop = []\n",
    "        # planned service time statistics\n",
    "        planned_service_time = []\n",
    "        # getting lat and lng for the source station\n",
    "        lat_lng.append((route['stops'][sequence[0]]['lat'], route['stops'][sequence[0]]['lng']))\n",
    "        for index in range(0, len(sequence)-1):\n",
    "            # variables used to check time window per stop\n",
    "            tw_start = 0\n",
    "            tw_end = 0\n",
    "            has_time_window = False\n",
    "            # travel time\n",
    "            travel_time += travel_times_data[routeID][sequence[index]][sequence[index+1]]\n",
    "            # saving time between each stop to build features at the end\n",
    "            time_between_stops.append(travel_times_data[routeID][sequence[index]][sequence[index+1]])\n",
    "\n",
    "            lat_lng.append((route['stops'][sequence[index + 1]]['lat'], route['stops'][sequence[index + 1]]['lng']))\n",
    "\n",
    "            # total number of packages per stop\n",
    "            packages_per_stop = 0\n",
    "            # total volume of packages per stop\n",
    "            package_volume_stop = 0\n",
    "            # stop sequence[0] is the delivery station. There are no packages to be delivery at this stop.\n",
    "            # compute time to delivery all packages from the same stop\n",
    "            service_time = 0\n",
    "\n",
    "            sort_packages = sorted(package_data[routeID][sequence[index+1]])\n",
    "            for pkg in sort_packages:\n",
    "                # counting total number of packages\n",
    "                package_count += 1\n",
    "                # counting number of packages in this stop\n",
    "                packages_per_stop += 1\n",
    "                # At this point, I am considering that planned_service_time_seconds is the same for all packages.\n",
    "                if package_data[routeID][sequence[index+1]][pkg]['planned_service_time_seconds']:\n",
    "                    service_time += package_data[routeID][sequence[index+1]][pkg]['planned_service_time_seconds']\n",
    "                    planned_service_time.append(package_data[routeID][sequence[index+1]][pkg]['planned_service_time_seconds'])\n",
    "                # if not (isinstance(package_data[routeID][sequence[index+1]][pkg]['time_window']['start_time_utc'], float) \\\n",
    "                #         and np.isnan(package_data[routeID][sequence[index+1]][pkg]['time_window']['start_time_utc'])):\n",
    "                if not isnan(package_data[routeID][sequence[index+1]][pkg]['time_window']['start_time_utc']):\n",
    "                    has_time_window = True\n",
    "\n",
    "                    tw_start = dt.datetime.strptime(package_data[routeID][sequence[index+1]][pkg]['time_window']\n",
    "                                                    ['start_time_utc'], '%Y-%m-%d %H:%M:%S')\n",
    "                    tw_end = dt.datetime.strptime(package_data[routeID][sequence[index+1]][pkg]['time_window']\n",
    "                                                  ['end_time_utc'], '%Y-%m-%d %H:%M:%S')\n",
    "                # I am considering that if depth_cm exists, than height_cm and width_cm also exist.\n",
    "                # if not (isinstance(package_data[routeID][sequence[index+1]][pkg]['dimensions']['depth_cm'], float) \\\n",
    "                #         and np.isnan(package_data[routeID][sequence[index+1]][pkg]['dimensions']['depth_cm'])):\n",
    "                if not isnan(package_data[routeID][sequence[index+1]][pkg]['dimensions']['depth_cm']):\n",
    "                    # package volume\n",
    "                    package_volume_stop += (package_data[routeID][sequence[index+1]][pkg]['dimensions']['depth_cm']\n",
    "                                            * package_data[routeID][sequence[index+1]][pkg]['dimensions']['height_cm']\n",
    "                                            * package_data[routeID][sequence[index+1]][pkg]['dimensions']['width_cm'])\n",
    "\n",
    "            # package data per stop - for statistics\n",
    "            packages_stat_per_stop.append(packages_per_stop)\n",
    "\n",
    "            # route total delivery time (packages)\n",
    "            delivery_time += service_time\n",
    "\n",
    "            # package volume per route\n",
    "            package_volume += package_volume_stop\n",
    "\n",
    "            # check time window for each stop:\n",
    "            if has_time_window:\n",
    "                # counting total number of packages with time window violation\n",
    "                package_count_violation += packages_per_stop\n",
    "                # time window for all stops (total em seconds)\n",
    "                tw_total += (tw_end - tw_start).total_seconds()\n",
    "                current_time = start_time + dt.timedelta(seconds=(travel_time + delivery_time))\n",
    "                # if current time is not in the window, mark as a violation\n",
    "                if not (tw_start <= current_time <= tw_end):\n",
    "                    tw_violated += 1\n",
    "                    package_count_total_violation += packages_per_stop\n",
    "                    if current_time < tw_start:\n",
    "                        tw_violated_early += 1\n",
    "                        difference += (tw_start - current_time).total_seconds()\n",
    "                        difference_early += (tw_start - current_time).total_seconds()\n",
    "                    else:  # current_time > tw_end\n",
    "                        # counting total number of packages with late time window violation\n",
    "                        package_count_late_violation += packages_per_stop\n",
    "                        # total volume of packages with late time window violation\n",
    "                        package_volume_late_violation += package_volume_stop\n",
    "                        tw_violated_late += 1\n",
    "                        difference += (current_time - tw_end).total_seconds()\n",
    "                        difference_late += (current_time - tw_end).total_seconds()\n",
    "\n",
    "            # get data about zones\n",
    "            zone_id = route['stops'][sequence[index + 1]]['zone_id']\n",
    "            if not isnan(zone_id):\n",
    "                # backtracking: zone_id is in the sequence of zones visited, but it was not the last one\n",
    "                if zone_id in zones:\n",
    "                    if zone_id != zones[len(zones)-1]:\n",
    "                        backtracking += 1\n",
    "                else:  # zone_id was never visited before\n",
    "                    unique_zones += 1\n",
    "                zones.append(zone_id)\n",
    "\n",
    "        # package data per stop - statistics\n",
    "        features[\"min_packages_per_stop\"] = min(packages_stat_per_stop)\n",
    "        features[\"max_packages_per_stop\"] = max(packages_stat_per_stop)\n",
    "        features[\"std_packages_per_stop\"] = statistics.stdev(packages_stat_per_stop)\n",
    "        features[\"median_packages_per_stop\"] = statistics.median(packages_stat_per_stop)\n",
    "        features[\"mean_packages_per_stop\"] = statistics.mean(packages_stat_per_stop)\n",
    "\n",
    "        # time between stops features\n",
    "        features[\"min_time_btw_stops\"] = min(time_between_stops)\n",
    "        features[\"max_time_btw_stops\"] = max(time_between_stops)\n",
    "        features[\"std_time_btw_stops\"] = statistics.stdev(time_between_stops)\n",
    "        features[\"median_time_btw_stops\"] = statistics.median(time_between_stops)\n",
    "        features[\"mean_time_btw_stops\"] = statistics.mean(time_between_stops)\n",
    "\n",
    "        # planned service time statistics\n",
    "        features[\"min_planned_service_time\"] = min(planned_service_time)\n",
    "        features[\"max_planned_service_time\"] = max(planned_service_time)\n",
    "        features[\"std_planned_service_time\"] = statistics.stdev(planned_service_time)\n",
    "        features[\"median_planned_service_time\"] = statistics.median(planned_service_time)\n",
    "        features[\"mean_planned_service_time\"] = statistics.mean(planned_service_time)\n",
    "\n",
    "        # total planned service time\n",
    "        features[\"total_planned_service_time\"] = delivery_time\n",
    "        # ratio_packages_planned_service: ratio between packages count and planned service time\n",
    "        features[\"ratio_packages_planned_service\"] = package_count/delivery_time\n",
    "        # ratio_package_volume_planned_service: ratio between package volume and planned service time\n",
    "        features[\"ratio_package_volume_planned_service\"] = package_volume/delivery_time\n",
    "\n",
    "        # total delivery time = travel_time + delivery_time\n",
    "        total_delivery_time = travel_time + delivery_time\n",
    "        # total_delivery_time: route total time (distance + time for package delivery)\n",
    "        features['total_delivery_time'] = total_delivery_time\n",
    "        # travel_time: time to travel between stops (distance)\n",
    "        features['travel_time'] = travel_time\n",
    "\n",
    "        # violation_count: window violation count\n",
    "        features['violation_count'] = tw_violated\n",
    "        # violation_total_time: window violation total time (em seconds)\n",
    "        features['violation_total_time'] = difference\n",
    "        # violation_avg_time: window violation average time (em seconds)\n",
    "        if tw_violated != 0:\n",
    "            features['violation_avg_time'] = difference/tw_violated\n",
    "        else:\n",
    "            features['violation_avg_time'] = 0\n",
    "        # ratio_violation_w_total_time: ratio between window violation time and window total time\n",
    "        if tw_total != 0:\n",
    "            features['ratio_violation_w_total_time'] = difference/tw_total\n",
    "        else:\n",
    "            features['ratio_violation_w_total_time'] = 0\n",
    "        # violation_early_total_time: window violation total time - arrived early (time in seconds)\n",
    "        features['violation_early_total_time'] = difference_early\n",
    "        # violation_late_total_time: window violation total time - arrived late (time in seconds)\n",
    "        features['violation_late_total_time'] = difference_late\n",
    "        # violation_early_count:  window violation count - arrived early\n",
    "        features['violation_early_count'] = tw_violated_early\n",
    "        # violation_late_count: window violation time - arrived late\n",
    "        features['violation_late_count'] = tw_violated_late\n",
    "        # violation_early_avg_time: window violation avg time - arrived early (time in seconds)\n",
    "        if tw_violated_early != 0:\n",
    "            features['violation_early_avg_time'] = difference_early / tw_violated_early\n",
    "        else:\n",
    "            features['violation_early_avg_time'] = 0\n",
    "        # violation_late_avg_time: window violation avg time - arrived late (time in seconds)\n",
    "        if tw_violated_late != 0:\n",
    "            features['violation_late_avg_time'] = difference_late / tw_violated_late\n",
    "        else:\n",
    "            features['violation_late_avg_time'] = 0\n",
    "        # ratio_early_violation: ratio between window violation time and window total time - arrived early\n",
    "        # ratio_late_violation: ratio between window violation time and window total time - arrived late\n",
    "        if tw_total != 0:\n",
    "            features['ratio_early_violation'] = difference_early/tw_total\n",
    "            features['ratio_late_violation'] = difference_late / tw_total\n",
    "        else:\n",
    "            features['ratio_early_violation'] = 0\n",
    "            features['ratio_late_violation'] = 0\n",
    "\n",
    "        # ratio_delivery_time_stops: ratio between delivery time and number of stops\n",
    "        features['ratio_delivery_time_stops'] = total_delivery_time/route_size\n",
    "        # ratio_zones_delivery_time: ratio between number of unique zones and delivery time\n",
    "        features['ratio_zones_delivery_time'] = unique_zones/total_delivery_time\n",
    "        # ratio_route_size_delivery_time: ratio between route size (number of stops) and delivery time\n",
    "        features['ratio_route_size_delivery_time'] = route_size/total_delivery_time\n",
    "        # ratio_packages_count_delivery_time: ratio between number of packages and delivery time\n",
    "        features['ratio_packages_count_delivery_time'] = package_count/total_delivery_time\n",
    "        # ratio_violation_delivery_time: ratio between window violation count and delivery time (route size)\n",
    "        features['ratio_violation_delivery_time'] = tw_violated/total_delivery_time\n",
    "        # ratio_delivery_time_packages_count: ratio between delivery time and number of packages\n",
    "        features['ratio_delivery_time_packages_count'] = total_delivery_time/package_count\n",
    "\n",
    "        # backtracking_count: backtracking count (number of times a driver leaves and then goes back to a zone)\n",
    "        features['backtracking_count'] = backtracking\n",
    "        # ratio_backtracking_travel_time: ration between backtracking count and travel time\n",
    "        features[\"ratio_backtracking_travel_time\"] = backtracking/travel_time\n",
    "        # ratio_backtracking_delivery_time: ration between backtracking count and travel time\n",
    "        features[\"ratio_backtracking_delivery_time\"] = backtracking/total_delivery_time\n",
    "\n",
    "\n",
    "        # zones_count: number of unique zones per route\n",
    "        features['zones_count'] = unique_zones\n",
    "        # ratio_backtracking_route_size: ratio between backtracking count and route size\n",
    "        features['ratio_backtracking_route_size'] = backtracking/len(sequence)\n",
    "        # ration_backtracking_route_zones: ratio between backtracking count and number of unique zones in a route\n",
    "        features['ratio_backtracking_route_zones'] = backtracking/unique_zones\n",
    "        # ratio_zones_route_size: ratio between number of unique zones and route size (number of stops per route)\n",
    "        features['ratio_zones_route_size'] = unique_zones/route_size\n",
    "        # ratio_zones_travel_time: ratio between number of unique zones and travel time\n",
    "        features['ratio_zones_travel_time'] = unique_zones/travel_time\n",
    "        # ratio_route_size_travel_time: ratio between route size (number of stops) and travel time\n",
    "        features['ratio_route_size_travel_time'] = route_size/travel_time\n",
    "\n",
    "        # ratio_packages_count_travel_time: ratio between number of packages and total travel_time\n",
    "        features['ratio_packages_count_travel_time'] = package_count/travel_time\n",
    "        # ratio_packages_count_route_size: ratio between number of packages and route size (number of stops)\n",
    "        features['ratio_packages_count_travel_time'] = package_count/route_size\n",
    "        # ratio_violation_travel_time: ratio between window violation count and travel time\n",
    "        features['ratio_violation_travel_time'] = tw_violated/travel_time\n",
    "        # ratio_travel_time_stops: ratio between travel time and number of stops (route size)\n",
    "        features['ratio_travel_time_stops'] = travel_time/route_size\n",
    "        # ratio_travel_time_packages_count: ratio between travel time and number of packages\n",
    "        features['ratio_travel_time_packages_count'] = travel_time/package_count\n",
    "        # ratio_package_count_violation_avg_time: ratio between packages count and window violation total time\n",
    "        if tw_violated != 0:\n",
    "            features['ratio_package_count_violation_avg_time'] = package_count_violation/difference\n",
    "        else:\n",
    "            features['ratio_package_count_violation_avg_time'] = 0\n",
    "\n",
    "        # ratio_package_count_violation_total_time: ratio between average number of packages (not delivered on time)\n",
    "        # and window violation average time\n",
    "        if tw_violated != 0:\n",
    "            features['ratio_package_count_violation_total_time'] = package_count_total_violation/difference\n",
    "        else:\n",
    "            features['ratio_package_count_violation_total_time'] = 0\n",
    "\n",
    "\n",
    "        # ratio_package_count_violation_late_avg_time: ratio between avg packages count (delivered late) and window\n",
    "        # violation (late) average time\n",
    "        if difference_late != 0:\n",
    "            features['ratio_package_count_violation_late_avg_time'] = (package_count_late_violation /\n",
    "                                                                       tw_violated_late)/(difference_late /\n",
    "                                                                                          tw_violated_late)\n",
    "        else:\n",
    "            features['ratio_package_count_violation_late_avg_time'] = 0\n",
    "        # ratio_package_count_violation_late_total_time: ration between total packages count (delivered late) and\n",
    "        # window violation (late) total time\n",
    "        if difference_late != 0:\n",
    "            features['ratio_package_count_violation_late_total_time'] = package_count_late_violation/difference_late\n",
    "        else:\n",
    "            features['ratio_package_count_violation_late_total_time'] = 0\n",
    "        # ratio_package_volume_delivery_time: ratio between packages volume and total delivery time\n",
    "        features['ratio_package_volume_delivery_time'] = package_volume/total_delivery_time\n",
    "        # ratio_package_volume_violation_time: ratio between packages volume (not delivered on time) and window violation\n",
    "        #         total time\n",
    "        if tw_violated != 0:\n",
    "            features['ratio_package_volume_violation_time'] = package_volume_late_violation/difference\n",
    "        else:\n",
    "            features['ratio_package_volume_violation_time'] = 0\n",
    "        # ratio_package_volume_violation_late_total_time: ratio between packages (not delivered on time) volume and\n",
    "        # window violation (late) total time\n",
    "        if difference_late != 0:\n",
    "            features['ratio_package_volume_violation_late_total_time'] = package_volume_late_violation/difference_late\n",
    "        else:\n",
    "            features['ratio_package_volume_violation_late_total_time'] = 0\n",
    "\n",
    "        rush_hour = [(dt.time(7), dt.time(9)), (dt.time(17), dt.time(19))]\n",
    "        # rush_hour_morning (7am-9am)\n",
    "        end_route = start_time + dt.timedelta(seconds=total_delivery_time)\n",
    "        features['rush_hour_morning'] = time_in_between(rush_hour=rush_hour[0], start_route=start_time.time(),\n",
    "                                                             end_route=end_route.time())\n",
    "        # rush_hour_evening (5pm-7pm)\n",
    "        features['rush_hour_evening'] = time_in_between(rush_hour=rush_hour[1], start_route=start_time.time(),\n",
    "                                                             end_route=end_route.time())\n",
    "\n",
    "        features['area'] = compute_area(lat_lng)\n",
    "\n",
    "        if phase == 'build':\n",
    "            # label: route_score (HIGH, MEDIUM, LOW)\n",
    "            features['route_score'] = route['route_score']\n",
    "        all_features.append(features)\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(all_features)\n",
    "\n",
    "    # TODO: Features and labels can be return to feed the classifier.\n",
    "    # For now, I am saving them in a file called features.json\n",
    "    # return all_features\n",
    "\n",
    "    # only for test\n",
    "    with open(features_file, \"w\") as feature_file:\n",
    "        # Serializing json\n",
    "        json_object = json.dumps(all_features)\n",
    "        # Writing features into a file, only for test\n",
    "        feature_file.write(json_object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d728849",
   "metadata": {},
   "source": [
    "**Load the data and create new features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7d38425",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./data/almrrc2021-data-training/model_build_inputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cfe68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data = load_data(root_path+'route_data.json')\n",
    "package_data = load_data(root_path+'package_data.json')\n",
    "travel_times_data = load_data(root_path+'travel_times.json')\n",
    "actual_sequences_data = load_data(root_path+'actual_sequences.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc7aa92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f43d037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['routeID', 'route_size', 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
       "       'Friday', 'Saturday', 'Sunday', 'min_packages_per_stop',\n",
       "       'max_packages_per_stop', 'std_packages_per_stop',\n",
       "       'median_packages_per_stop', 'mean_packages_per_stop',\n",
       "       'min_time_btw_stops', 'max_time_btw_stops', 'std_time_btw_stops',\n",
       "       'median_time_btw_stops', 'mean_time_btw_stops',\n",
       "       'min_planned_service_time', 'max_planned_service_time',\n",
       "       'std_planned_service_time', 'median_planned_service_time',\n",
       "       'mean_planned_service_time', 'total_planned_service_time',\n",
       "       'ratio_packages_planned_service',\n",
       "       'ratio_package_volume_planned_service', 'total_delivery_time',\n",
       "       'travel_time', 'violation_count', 'violation_total_time',\n",
       "       'violation_avg_time', 'ratio_violation_w_total_time',\n",
       "       'violation_early_total_time', 'violation_late_total_time',\n",
       "       'violation_early_count', 'violation_late_count',\n",
       "       'violation_early_avg_time', 'violation_late_avg_time',\n",
       "       'ratio_early_violation', 'ratio_late_violation',\n",
       "       'ratio_delivery_time_stops', 'ratio_zones_delivery_time',\n",
       "       'ratio_route_size_delivery_time', 'ratio_packages_count_delivery_time',\n",
       "       'ratio_violation_delivery_time', 'ratio_delivery_time_packages_count',\n",
       "       'backtracking_count', 'ratio_backtracking_travel_time',\n",
       "       'ratio_backtracking_delivery_time', 'zones_count',\n",
       "       'ratio_backtracking_route_size', 'ratio_backtracking_route_zones',\n",
       "       'ratio_zones_route_size', 'ratio_zones_travel_time',\n",
       "       'ratio_route_size_travel_time', 'ratio_packages_count_travel_time',\n",
       "       'ratio_violation_travel_time', 'ratio_travel_time_stops',\n",
       "       'ratio_travel_time_packages_count',\n",
       "       'ratio_package_count_violation_avg_time',\n",
       "       'ratio_package_count_violation_total_time',\n",
       "       'ratio_package_count_violation_late_avg_time',\n",
       "       'ratio_package_count_violation_late_total_time',\n",
       "       'ratio_package_volume_delivery_time',\n",
       "       'ratio_package_volume_violation_time',\n",
       "       'ratio_package_volume_violation_late_total_time', 'rush_hour_morning',\n",
       "       'rush_hour_evening', 'area', 'route_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc789c50",
   "metadata": {},
   "source": [
    "**Training a classifier**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5e439",
   "metadata": {},
   "source": [
    "Checking how many samples we have for each label: low, medium, and high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7889045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    3292\n",
       "High      2718\n",
       "Low        102\n",
       "Name: route_score, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_json(root_path+'route_data.json', orient='index')\n",
    "df['route_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67c5ceda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArQElEQVR4nO3df1RU953/8dcI4ygGRpEywAZd21hXi7GNJojNBowCmiCx9kRP3GW1sWpXxSVobdR4gptEW0+/6h5NXeu6iqI152xj0z2xBDyNph78SUKjLmttqoluQKzFQRSHEe73jxzuccQfjBk6fvT5OIdzuJ/7vp/53NHPzIvPnQsOy7IsAQAAGKZLuAcAAABwNwgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjRYZ7AJ2ltbVVn3/+uaKjo+VwOMI9HAAA0AGWZenSpUtKSkpSly63X2u5b0PM559/ruTk5HAPAwAA3IUzZ87o4Ycfvm3NfRtioqOjJX3xJMTExIS0b7/fr7KyMmVlZcnpdIa0bwB3xhwEwq+z5mFDQ4OSk5Pt9/HbuW9DTNslpJiYmE4JMVFRUYqJieEFFAgD5iAQfp09DzvyURA+2AsAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgpMhwDwAA7lZK0XvytTjCPYwOO/3jZ8M9BOC+wkoMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYKagQs27dOj366KOKiYlRTEyM0tLS9Jvf/Mbeb1mWioqKlJSUpO7duysjI0PHjx8P6MPn8yk/P19xcXHq0aOHcnNzdfbs2YCa+vp65eXlye12y+12Ky8vTxcvXrz7swQAAPedoELMww8/rB//+Mc6cuSIjhw5oqefflrPPfecHVRWrFihlStXau3atTp8+LASEhKUmZmpS5cu2X0UFBRo586d2rFjh/bt26fGxkbl5OSopaXFrpk8ebKqqqpUWlqq0tJSVVVVKS8vL0SnDAAA7geRwRSPGzcuYPuNN97QunXrdODAAQ0aNEirV6/W4sWLNWHCBElScXGxPB6Ptm/frpkzZ8rr9Wrjxo3aunWrRo8eLUkqKSlRcnKydu/erezsbFVXV6u0tFQHDhxQamqqJGnDhg1KS0vTiRMnNGDAgFCcNwAAMNxdfyampaVFO3bs0OXLl5WWlqZTp06ptrZWWVlZdo3L5VJ6eroqKiokSZWVlfL7/QE1SUlJSklJsWv2798vt9ttBxhJGj58uNxut10DAAAQ1EqMJB09elRpaWm6evWqHnroIe3cuVODBg2yA4bH4wmo93g8+vTTTyVJtbW16tq1q3r16tWupra21q6Jj49v97jx8fF2zc34fD75fD57u6GhQZLk9/vl9/uDPc3bausv1P0C6Ji2uefqYoV5JMHhNQP3k856Lwymv6BDzIABA1RVVaWLFy/ql7/8paZMmaK9e/fa+x0OR0C9ZVnt2m50Y83N6u/Uz/Lly7V06dJ27WVlZYqKirrt49+t8vLyTukXQMe8Nqw13EMIyq5du8I9BCDkQv1eeOXKlQ7XBh1iunbtqkceeUSSNGzYMB0+fFj/9m//ph/96EeSvlhJSUxMtOvr6urs1ZmEhAQ1Nzervr4+YDWmrq5OI0aMsGvOnTvX7nHPnz/fbpXnegsXLlRhYaG93dDQoOTkZGVlZSkmJibY07wtv9+v8vJyZWZmyul0hrRvAHfWNgeXHOkiX+vtf0i6lxwryg73EICQ6az3wrYrKR0RdIi5kWVZ8vl86tevnxISElReXq5vfetbkqTm5mbt3btXP/nJTyRJQ4cOldPpVHl5uSZOnChJqqmp0bFjx7RixQpJUlpamrxerw4dOqQnnnhCknTw4EF5vV476NyMy+WSy+Vq1+50OjstaHRm3wDuzNfqkK/FnBDD6wXuR6F+Lwymr6BCzKJFizR27FglJyfr0qVL2rFjh/bs2aPS0lI5HA4VFBRo2bJl6t+/v/r3769ly5YpKipKkydPliS53W5NmzZN8+bNU+/evRUbG6v58+dr8ODB9t1KAwcO1JgxYzR9+nStX79ekjRjxgzl5ORwZxIAALAFFWLOnTunvLw81dTUyO1269FHH1VpaakyMzMlSQsWLFBTU5NmzZql+vp6paamqqysTNHR0XYfq1atUmRkpCZOnKimpiaNGjVKmzdvVkREhF2zbds2zZ07176LKTc3V2vXrg3F+QIAgPuEw7Issz7e30ENDQ1yu93yer2d8pmYXbt26ZlnnmF5GAiDtjm44FCEUZeTTv/42XAPAQiZznovDOb9m7+dBAAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGCky3AMwWUrRe/K1OMI9jA47/eNnwz0EAABChpUYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMFJQIWb58uV6/PHHFR0drfj4eI0fP14nTpwIqJk6daocDkfA1/DhwwNqfD6f8vPzFRcXpx49eig3N1dnz54NqKmvr1deXp7cbrfcbrfy8vJ08eLFuztLAABw3wkqxOzdu1ezZ8/WgQMHVF5ermvXrikrK0uXL18OqBszZoxqamrsr127dgXsLygo0M6dO7Vjxw7t27dPjY2NysnJUUtLi10zefJkVVVVqbS0VKWlpaqqqlJeXt6XOFUAAHA/iQymuLS0NGB706ZNio+PV2VlpZ566im73eVyKSEh4aZ9eL1ebdy4UVu3btXo0aMlSSUlJUpOTtbu3buVnZ2t6upqlZaW6sCBA0pNTZUkbdiwQWlpaTpx4oQGDBgQ1EkCAID7T1Ah5kZer1eSFBsbG9C+Z88excfHq2fPnkpPT9cbb7yh+Ph4SVJlZaX8fr+ysrLs+qSkJKWkpKiiokLZ2dnav3+/3G63HWAkafjw4XK73aqoqLhpiPH5fPL5fPZ2Q0ODJMnv98vv93+Z02ynrT9XFyuk/Xa2UD8PQLgwB4Hwa/v/3FnvsR1x1yHGsiwVFhbqySefVEpKit0+duxYPf/88+rbt69OnTqlJUuW6Omnn1ZlZaVcLpdqa2vVtWtX9erVK6A/j8ej2tpaSVJtba0deq4XHx9v19xo+fLlWrp0abv2srIyRUVF3e1p3tZrw1o7pd/OcuNlPcB0zEEg/MrLy0Pa35UrVzpce9chZs6cOfr444+1b9++gPZJkybZ36ekpGjYsGHq27ev3n33XU2YMOGW/VmWJYfDYW9f//2taq63cOFCFRYW2tsNDQ1KTk5WVlaWYmJiOnxeHeH3+1VeXq4lR7rI13rz8dyLjhVlh3sIQEgwB4Hwa5uHmZmZcjqdIeu37UpKR9xViMnPz9evf/1rffDBB3r44YdvW5uYmKi+ffvq5MmTkqSEhAQ1Nzervr4+YDWmrq5OI0aMsGvOnTvXrq/z58/L4/Hc9HFcLpdcLle7dqfTGdIn93q+Vod8Lea8gHbW8wCEC3MQCL9Qv88G01dQdydZlqU5c+bo7bff1m9/+1v169fvjsdcuHBBZ86cUWJioiRp6NChcjqdActPNTU1OnbsmB1i0tLS5PV6dejQIbvm4MGD8nq9dg0AAHiwBbUSM3v2bG3fvl3vvPOOoqOj7c+nuN1ude/eXY2NjSoqKtJ3v/tdJSYm6vTp01q0aJHi4uL0ne98x66dNm2a5s2bp969eys2Nlbz58/X4MGD7buVBg4cqDFjxmj69Olav369JGnGjBnKycnhziQAACApyBCzbt06SVJGRkZA+6ZNmzR16lRFRETo6NGj2rJliy5evKjExESNHDlSb731lqKjo+36VatWKTIyUhMnTlRTU5NGjRqlzZs3KyIiwq7Ztm2b5s6da9/FlJubq7Vr197teQIAgPtMUCHGsm5/O2P37t313nvv3bGfbt26ac2aNVqzZs0ta2JjY1VSUhLM8AAAwAOEv50EAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARgoqxCxfvlyPP/64oqOjFR8fr/Hjx+vEiRMBNZZlqaioSElJSerevbsyMjJ0/PjxgBqfz6f8/HzFxcWpR48eys3N1dmzZwNq6uvrlZeXJ7fbLbfbrby8PF28ePHuzhIAANx3ggoxe/fu1ezZs3XgwAGVl5fr2rVrysrK0uXLl+2aFStWaOXKlVq7dq0OHz6shIQEZWZm6tKlS3ZNQUGBdu7cqR07dmjfvn1qbGxUTk6OWlpa7JrJkyerqqpKpaWlKi0tVVVVlfLy8kJwygAA4H4QGUxxaWlpwPamTZsUHx+vyspKPfXUU7IsS6tXr9bixYs1YcIESVJxcbE8Ho+2b9+umTNnyuv1auPGjdq6datGjx4tSSopKVFycrJ2796t7OxsVVdXq7S0VAcOHFBqaqokacOGDUpLS9OJEyc0YMCAUJw7AAAwWFAh5kZer1eSFBsbK0k6deqUamtrlZWVZde4XC6lp6eroqJCM2fOVGVlpfx+f0BNUlKSUlJSVFFRoezsbO3fv19ut9sOMJI0fPhwud1uVVRU3DTE+Hw++Xw+e7uhoUGS5Pf75ff7v8xpttPWn6uLFdJ+O1uonwcgXJiDQPi1/X/urPfYjrjrEGNZlgoLC/Xkk08qJSVFklRbWytJ8ng8AbUej0effvqpXdO1a1f16tWrXU3b8bW1tYqPj2/3mPHx8XbNjZYvX66lS5e2ay8rK1NUVFSQZ9cxrw1r7ZR+O8uuXbvCPQQgpJiDQPiVl5eHtL8rV650uPauQ8ycOXP08ccfa9++fe32ORyOgG3Lstq13ejGmpvV366fhQsXqrCw0N5uaGhQcnKysrKyFBMTc9vHDpbf71d5ebmWHOkiX+vtz+tecqwoO9xDAEKCOQiEX9s8zMzMlNPpDFm/bVdSOuKuQkx+fr5+/etf64MPPtDDDz9styckJEj6YiUlMTHRbq+rq7NXZxISEtTc3Kz6+vqA1Zi6ujqNGDHCrjl37ly7xz1//ny7VZ42LpdLLperXbvT6Qzpk3s9X6tDvhZzXkA763kAwoU5CIRfqN9ng+krqLuTLMvSnDlz9Pbbb+u3v/2t+vXrF7C/X79+SkhICFhaam5u1t69e+2AMnToUDmdzoCampoaHTt2zK5JS0uT1+vVoUOH7JqDBw/K6/XaNQAA4MEW1ErM7NmztX37dr3zzjuKjo62P5/idrvVvXt3ORwOFRQUaNmyZerfv7/69++vZcuWKSoqSpMnT7Zrp02bpnnz5ql3796KjY3V/PnzNXjwYPtupYEDB2rMmDGaPn261q9fL0maMWOGcnJyuDMJAABICjLErFu3TpKUkZER0L5p0yZNnTpVkrRgwQI1NTVp1qxZqq+vV2pqqsrKyhQdHW3Xr1q1SpGRkZo4caKampo0atQobd68WREREXbNtm3bNHfuXPsuptzcXK1du/ZuzhEAANyHggoxlnXn2xkdDoeKiopUVFR0y5pu3bppzZo1WrNmzS1rYmNjVVJSEszwAADAA4S/nQQAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjBR1iPvjgA40bN05JSUlyOBz61a9+FbB/6tSpcjgcAV/Dhw8PqPH5fMrPz1dcXJx69Oih3NxcnT17NqCmvr5eeXl5crvdcrvdysvL08WLF4M+QQAAcH8KOsRcvnxZQ4YM0dq1a29ZM2bMGNXU1Nhfu3btCthfUFCgnTt3aseOHdq3b58aGxuVk5OjlpYWu2by5MmqqqpSaWmpSktLVVVVpby8vGCHCwAA7lORwR4wduxYjR079rY1LpdLCQkJN93n9Xq1ceNGbd26VaNHj5YklZSUKDk5Wbt371Z2draqq6tVWlqqAwcOKDU1VZK0YcMGpaWl6cSJExowYECwwwYAAPeZoENMR+zZs0fx8fHq2bOn0tPT9cYbbyg+Pl6SVFlZKb/fr6ysLLs+KSlJKSkpqqioUHZ2tvbv3y+3220HGEkaPny43G63KioqbhpifD6ffD6fvd3Q0CBJ8vv98vv9IT2/tv5cXayQ9tvZQv08AOHCHATCr+3/c2e9x3ZEyEPM2LFj9fzzz6tv3746deqUlixZoqefflqVlZVyuVyqra1V165d1atXr4DjPB6PamtrJUm1tbV26LlefHy8XXOj5cuXa+nSpe3ay8rKFBUVFYIza++1Ya2d0m9nufGyHmA65iAQfuXl5SHt78qVKx2uDXmImTRpkv19SkqKhg0bpr59++rdd9/VhAkTbnmcZVlyOBz29vXf36rmegsXLlRhYaG93dDQoOTkZGVlZSkmJuZuTuWW/H6/ysvLteRIF/labz6ee9GxouxwDwEICeYgEH5t8zAzM1NOpzNk/bZdSemITrmcdL3ExET17dtXJ0+elCQlJCSoublZ9fX1AasxdXV1GjFihF1z7ty5dn2dP39eHo/npo/jcrnkcrnatTudzpA+udfztTrkazHnBbSzngcgXJiDQPiF+n02mL46/ffEXLhwQWfOnFFiYqIkaejQoXI6nQHLTzU1NTp27JgdYtLS0uT1enXo0CG75uDBg/J6vXYNAAB4sAW9EtPY2Kg//vGP9vapU6dUVVWl2NhYxcbGqqioSN/97neVmJio06dPa9GiRYqLi9N3vvMdSZLb7da0adM0b9489e7dW7GxsZo/f74GDx5s3600cOBAjRkzRtOnT9f69eslSTNmzFBOTg53JgEAAEl3EWKOHDmikSNH2tttn0OZMmWK1q1bp6NHj2rLli26ePGiEhMTNXLkSL311luKjo62j1m1apUiIyM1ceJENTU1adSoUdq8ebMiIiLsmm3btmnu3Ln2XUy5ubm3/d00AADgwRJ0iMnIyJBl3fq2xvfee++OfXTr1k1r1qzRmjVrblkTGxurkpKSYIcHAAAeEPztJAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADBS0CHmgw8+0Lhx45SUlCSHw6Ff/epXAfsty1JRUZGSkpLUvXt3ZWRk6Pjx4wE1Pp9P+fn5iouLU48ePZSbm6uzZ88G1NTX1ysvL09ut1tut1t5eXm6ePFi0CcIAADuT0GHmMuXL2vIkCFau3btTfevWLFCK1eu1Nq1a3X48GElJCQoMzNTly5dsmsKCgq0c+dO7dixQ/v27VNjY6NycnLU0tJi10yePFlVVVUqLS1VaWmpqqqqlJeXdxenCAAA7keRwR4wduxYjR079qb7LMvS6tWrtXjxYk2YMEGSVFxcLI/Ho+3bt2vmzJnyer3auHGjtm7dqtGjR0uSSkpKlJycrN27dys7O1vV1dUqLS3VgQMHlJqaKknasGGD0tLSdOLECQ0YMOBuzxcAANwngg4xt3Pq1CnV1tYqKyvLbnO5XEpPT1dFRYVmzpypyspK+f3+gJqkpCSlpKSooqJC2dnZ2r9/v9xutx1gJGn48OFyu92qqKi4aYjx+Xzy+Xz2dkNDgyTJ7/fL7/eH8jTt/lxdrJD229lC/TwA4cIcBMKv7f9zZ73HdkRIQ0xtba0kyePxBLR7PB59+umndk3Xrl3Vq1evdjVtx9fW1io+Pr5d//Hx8XbNjZYvX66lS5e2ay8rK1NUVFTwJ9MBrw1r7ZR+O8uuXbvCPQQgpJiDQPiVl5eHtL8rV650uDakIaaNw+EI2LYsq13bjW6suVn97fpZuHChCgsL7e2GhgYlJycrKytLMTExwQz/jvx+v8rLy7XkSBf5Wm9/XveSY0XZ4R4CEBLMQSD82uZhZmamnE5nyPptu5LSESENMQkJCZK+WElJTEy02+vq6uzVmYSEBDU3N6u+vj5gNaaurk4jRoywa86dO9eu//Pnz7db5WnjcrnkcrnatTudzpA+udfztTrkazHnBbSzngcgXJiDQPiF+n02mL5C+nti+vXrp4SEhIClpebmZu3du9cOKEOHDpXT6Qyoqamp0bFjx+yatLQ0eb1eHTp0yK45ePCgvF6vXQMAAB5sQa/ENDY26o9//KO9ferUKVVVVSk2NlZ9+vRRQUGBli1bpv79+6t///5atmyZoqKiNHnyZEmS2+3WtGnTNG/ePPXu3VuxsbGaP3++Bg8ebN+tNHDgQI0ZM0bTp0/X+vXrJUkzZsxQTk4OdyYBAABJdxFijhw5opEjR9rbbZ9DmTJlijZv3qwFCxaoqalJs2bNUn19vVJTU1VWVqbo6Gj7mFWrVikyMlITJ05UU1OTRo0apc2bNysiIsKu2bZtm+bOnWvfxZSbm3vL300DAAAePEGHmIyMDFnWrW9rdDgcKioqUlFR0S1runXrpjVr1mjNmjW3rImNjVVJSUmwwwMAAA8I/nYSAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjBTyEFNUVCSHwxHwlZCQYO+3LEtFRUVKSkpS9+7dlZGRoePHjwf04fP5lJ+fr7i4OPXo0UO5ubk6e/ZsqIcKAAAM1ikrMd/4xjdUU1Njfx09etTet2LFCq1cuVJr167V4cOHlZCQoMzMTF26dMmuKSgo0M6dO7Vjxw7t27dPjY2NysnJUUtLS2cMFwAAGCiyUzqNjAxYfWljWZZWr16txYsXa8KECZKk4uJieTwebd++XTNnzpTX69XGjRu1detWjR49WpJUUlKi5ORk7d69W9nZ2Z0xZAAAYJhOCTEnT55UUlKSXC6XUlNTtWzZMn31q1/VqVOnVFtbq6ysLLvW5XIpPT1dFRUVmjlzpiorK+X3+wNqkpKSlJKSooqKiluGGJ/PJ5/PZ283NDRIkvx+v/x+f0jPr60/VxcrpP12tlA/D0C4MAeB8Gv7/9xZ77EdEfIQk5qaqi1btujrX/+6zp07p9dff10jRozQ8ePHVVtbK0nyeDwBx3g8Hn366aeSpNraWnXt2lW9evVqV9N2/M0sX75cS5cubddeVlamqKioL3taN/XasNZO6bez7Nq1K9xDAEKKOQiEX3l5eUj7u3LlSodrQx5ixo4da38/ePBgpaWl6Wtf+5qKi4s1fPhwSZLD4Qg4xrKsdm03ulPNwoULVVhYaG83NDQoOTlZWVlZiomJuZtTuSW/36/y8nItOdJFvtbbj/tecqyIS3G4PzAHgfBrm4eZmZlyOp0h67ftSkpHdMrlpOv16NFDgwcP1smTJzV+/HhJX6y2JCYm2jV1dXX26kxCQoKam5tVX18fsBpTV1enESNG3PJxXC6XXC5Xu3an0xnSJ/d6vlaHfC3mvIB21vMAhAtzEAi/UL/PBtNXp/+eGJ/Pp+rqaiUmJqpfv35KSEgIWHpqbm7W3r177YAydOhQOZ3OgJqamhodO3bstiEGAAA8WEK+EjN//nyNGzdOffr0UV1dnV5//XU1NDRoypQpcjgcKigo0LJly9S/f3/1799fy5YtU1RUlCZPnixJcrvdmjZtmubNm6fevXsrNjZW8+fP1+DBg+27lQAAAEIeYs6ePasXXnhBf/7zn/WVr3xFw4cP14EDB9S3b19J0oIFC9TU1KRZs2apvr5eqampKisrU3R0tN3HqlWrFBkZqYkTJ6qpqUmjRo3S5s2bFREREerhAgAAQ4U8xOzYseO2+x0Oh4qKilRUVHTLmm7dumnNmjVas2ZNiEcHAADuF/ztJAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYKTLcAwAAANLfvvxuuIcQFFeEpRVPhHcMrMQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABjpng8xP/vZz9SvXz9169ZNQ4cO1e9+97twDwkAANwD7ukQ89Zbb6mgoECLFy/WRx99pL//+7/X2LFj9dlnn4V7aAAAIMzu6RCzcuVKTZs2Td///vc1cOBArV69WsnJyVq3bl24hwYAAMLsnv2Nvc3NzaqsrNTLL78c0J6VlaWKiop29T6fTz6fz972er2SpL/85S/y+/0hHZvf79eVK1cU6e+illZHSPvuTBcuXAj3EICQYA7ifhR57XK4hxCUyFZLV6606sKFC3I6nSHr99KlS5Iky7LuPIaQPWqI/fnPf1ZLS4s8Hk9Au8fjUW1tbbv65cuXa+nSpe3a+/Xr12ljNE3c/wv3CIAHG3MQ95vJndj3pUuX5Ha7b1tzz4aYNg5H4E9ZlmW1a5OkhQsXqrCw0N5ubW3VX/7yF/Xu3fum9V9GQ0ODkpOTdebMGcXExIS0bwB3xhwEwq+z5qFlWbp06ZKSkpLuWHvPhpi4uDhFRES0W3Wpq6trtzojSS6XSy6XK6CtZ8+enTlExcTE8AIKhBFzEAi/zpiHd1qBaXPPfrC3a9euGjp0qMrLywPay8vLNWLEiDCNCgAA3Cvu2ZUYSSosLFReXp6GDRumtLQ0/fznP9dnn32mH/zgB+EeGgAACLN7OsRMmjRJFy5c0L/+67+qpqZGKSkp2rVrl/r27RvWcblcLr366qvtLl8B+OtgDgLhdy/MQ4fVkXuYAAAA7jH37GdiAAAAbocQAwAAjESIAQAARiLE3MHmzZuD/n0zU6dO1fjx4ztlPMCDbs+ePXI4HLp48aKku5ujAO4PD3SIuVXYuP5FctKkSfrDH/7w1x8cYKipU6fK4XDc9FchzJo1Sw6HQ1OnTg3Z4zFHgdAw8QfwBzrEdET37t0VHx8f7mEARklOTtaOHTvU1NRkt129elW/+MUv1KdPn5A+FnMUeHARYu7gZkvVr7/+uuLj4xUdHa3vf//7evnll/XNb36z3bE//elPlZiYqN69e2v27Nkh/2vawL3qscceU58+ffT222/bbW+//baSk5P1rW99y26zLEsrVqzQV7/6VXXv3l1DhgzRf/3XfwX0tWvXLn39619X9+7dNXLkSJ0+fTpg/41z9GY/TRYUFCgjI8PezsjIUH5+vgoKCtSrVy95PB79/Oc/1+XLl/W9731P0dHR+trXvqbf/OY3X/q5AO4He/fu1RNPPCGXy6XExES9/PLLunbtmiTpv//7v9WzZ0+1trZKkqqqquRwOPTDH/7QPn7mzJl64YUXQj4uQkyQtm3bpjfeeEM/+clPVFlZqT59+mjdunXt6t5//3198sknev/991VcXKzNmzdr8+bNf/0BA2Hyve99T5s2bbK3//M//1MvvvhiQM0rr7yiTZs2ad26dTp+/Lheeukl/eM//qP27t0rSTpz5owmTJigZ555RlVVVfYPDaFQXFysuLg4HTp0SPn5+frnf/5nPf/88xoxYoQ+/PBDZWdnKy8vT1euXAnJ4wGm+r//+z8988wzevzxx/X73/9e69at08aNG/X6669Lkp566ildunRJH330kaQvAk9cXJw9j6UvPqaRnp4e+sFZD7ApU6ZYERERVo8ePQK+unXrZkmy6uvrrU2bNllut9s+JjU11Zo9e3ZAP9/+9retIUOGBPTbt29f69q1a3bb888/b02aNKmzTwkIuylTpljPPfecdf78ecvlclmnTp2yTp8+bXXr1s06f/689dxzz1lTpkyxGhsbrW7dulkVFRUBx0+bNs164YUXLMuyrIULF1oDBw60Wltb7f0/+tGP7PlpWVa7Odr2+Nf7l3/5Fys9Pd3eTk9Pt5588kl7+9q1a1aPHj2svLw8u62mpsaSZO3fv/9LPiOAGW42dyzLshYtWmQNGDAgYB6++eab1kMPPWS1tLRYlmVZjz32mPXTn/7UsizLGj9+vPXGG29YXbt2tRoaGuy5VF1dHfIxP/ArMSNHjlRVVVXA13/8x3/csv7EiRN64oknAtpu3Jakb3zjG4qIiLC3ExMTVVdXF7qBA/e4uLg4PfvssyouLtamTZv07LPPKi4uzt7/P//zP7p69aoyMzP10EMP2V9btmzRJ598Ikmqrq7W8OHD5XA47OPS0tJCMr5HH33U/j4iIkK9e/fW4MGD7TaPxyNJzFs88Kqrq5WWlhYwD7/97W+rsbFRZ8+elfTFJdo9e/bIsiz97ne/03PPPaeUlBTt27dP77//vjwej/7u7/4u5GO7p/920l9Djx499MgjjwS0tf2j3Mr1/5DSF9f1b+R0Otsd03a9EHhQvPjii5ozZ44k6c033wzY1zYf3n33Xf3N3/xNwL62v8Vys7l1J126dGl33M0+j3azOXp9W9s8Z97iQWdZ1i3f99raMzIytHHjRv3+979Xly5dNGjQIKWnp2vv3r2qr6/vnEtJ4jMxQRswYIAOHToU0HbkyJEwjQa4t40ZM0bNzc1qbm5WdnZ2wL5BgwbJ5XLps88+0yOPPBLwlZycbNccOHAg4Lgbt2/0la98RTU1NQFtVVVVX/5kgAfUoEGDVFFREfDDQUVFhaKjo+0fQNo+F7N69Wqlp6fL4XAoPT1de/bs6bzPw4gQE7T8/Hxt3LhRxcXFOnnypF5//XV9/PHH7VIqgC8u01RXV6u6ujrg8qokRUdHa/78+XrppZdUXFysTz75RB999JHefPNNFRcXS5J+8IMf6JNPPlFhYaFOnDih7du33/ED8k8//bSOHDmiLVu26OTJk3r11Vd17NixzjpF4L7i9XrbfcRixowZOnPmjPLz8/W///u/euedd/Tqq6+qsLBQXbp8ESPcbre++c1vqqSkxL4T8KmnntKHH36oP/zhDwF3B4bSA385KVj/8A//oD/96U+aP3++rl69qokTJ2rq1KntVmcAfCEmJuaW+1577TXFx8dr+fLl+tOf/qSePXvqscce06JFiyRJffr00S9/+Uu99NJL+tnPfqYnnnhCy5Yta3eX0/Wys7O1ZMkSLViwQFevXtWLL76of/qnf9LRo0dDfm7A/WbPnj0BvwZBkqZMmaJdu3bphz/8oYYMGaLY2FhNmzZNr7zySkDdyJEj9eGHH9qBpVevXho0aJA+//xzDRw4sFPG67Du5qIzAmRmZiohIUFbt24N91AAAHhgsBITpCtXrujf//3flZ2drYiICP3iF7/Q7t27VV5eHu6hAQDwQGElJkhNTU0aN26cPvzwQ/l8Pg0YMECvvPKKJkyYEO6hAQDwQCHEAAAAI3F3EgAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAw0v8HLQ/cnV3Wvf0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['route_score'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004de80",
   "metadata": {},
   "source": [
    "We can see that we are dealing with an imbalanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1470b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map for the labels - High: 0, Medium: 1, Low = 2\n",
    "label_dict = {\"High\": 0, \"Medium\": 1, \"Low\": 2}\n",
    "df['labels'] = df['route_score'].map(label_dict, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f10653ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.loc[:, df.columns.difference(['routeID', 'route_score', 'labels'])].values\n",
    "# labels\n",
    "y = df.loc[:, 'labels']\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4f6fc",
   "metadata": {},
   "source": [
    "**Multiclass classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "833b96e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.59       272\n",
      "           1       0.66      0.76      0.71       330\n",
      "           2       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.66       612\n",
      "   macro avg       0.69      0.54      0.58       612\n",
      "weighted avg       0.66      0.66      0.65       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, stratify=y)\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# scale training data\n",
    "X_train = scaler.transform(X_train)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95494e14",
   "metadata": {},
   "source": [
    "Trying under and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "247234d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2633), (1, 2633), (2, 2633)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.31      0.37       272\n",
      "           1       0.53      0.34      0.41       330\n",
      "           2       0.01      0.20      0.02        10\n",
      "\n",
      "    accuracy                           0.32       612\n",
      "   macro avg       0.33      0.28      0.27       612\n",
      "weighted avg       0.49      0.32      0.39       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "ros = SMOTE(random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# this is just to check if now the 2 classes are equally distributed\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resampled)\n",
    "# scale training data\n",
    "X_resampled = scaler.transform(X_resampled)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bdf0522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 82), (1, 82), (2, 82)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.62      0.51       272\n",
      "           1       0.39      0.04      0.08       330\n",
      "           2       0.03      0.50      0.05        10\n",
      "\n",
      "    accuracy                           0.31       612\n",
      "   macro avg       0.28      0.39      0.21       612\n",
      "weighted avg       0.40      0.31      0.27       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "ros = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# this is just to check if now the 2 classes are equally distributed\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resampled)\n",
    "# scale training data\n",
    "X_resampled = scaler.transform(X_resampled)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a9159",
   "metadata": {},
   "source": [
    "**Binary classifier**\n",
    "\n",
    "\n",
    "In this approach, we will treat the data is a binary dataset by mapping the high class to 0 and medium and low to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1996632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map for the labels - Binary classification: High: 0, Medium/Low = 1\n",
    "label_dict = {\"High\": 0, \"Medium\": 1, \"Low\": 1}\n",
    "df['labels'] = df['route_score'].map(label_dict, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20dbdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.loc[:, df.columns.difference(['routeID', 'route_score', 'labels'])].values\n",
    "# labels\n",
    "y = df.loc[:, 'labels']\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cddb0ff",
   "metadata": {},
   "source": [
    "Fitting a logistic regression model using the historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee507ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58       272\n",
      "           1       0.67      0.78      0.72       340\n",
      "\n",
      "    accuracy                           0.67       612\n",
      "   macro avg       0.66      0.65      0.65       612\n",
      "weighted avg       0.66      0.67      0.66       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, stratify=y)\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# scale training data\n",
    "X_train = scaler.transform(X_train)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3170e3",
   "metadata": {},
   "source": [
    "Trying over and under sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d56013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2715), (1, 2715)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.54       272\n",
      "           1       0.61      0.52      0.56       340\n",
      "\n",
      "    accuracy                           0.55       612\n",
      "   macro avg       0.55      0.55      0.55       612\n",
      "weighted avg       0.56      0.55      0.55       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "ros = SMOTE(random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# this is just to check if now the 2 classes are equally distributed\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resampled)\n",
    "# scale training data\n",
    "X_resampled = scaler.transform(X_resampled)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "481faafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2174), (1, 2174)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.26      0.30       272\n",
      "           1       0.52      0.64      0.57       340\n",
      "\n",
      "    accuracy                           0.47       612\n",
      "   macro avg       0.44      0.45      0.44       612\n",
      "weighted avg       0.45      0.47      0.45       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "ros = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# this is just to check if now the 2 classes are equally distributed\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resampled)\n",
    "# scale training data\n",
    "X_resampled = scaler.transform(X_resampled)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6897914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2271), (1, 2271)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.65      0.56       272\n",
      "           1       0.62      0.45      0.52       340\n",
      "\n",
      "    accuracy                           0.54       612\n",
      "   macro avg       0.55      0.55      0.54       612\n",
      "weighted avg       0.56      0.54      0.54       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "ros = SMOTETomek(random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# this is just to check if now the 2 classes are equally distributed\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resampled)\n",
    "# scale training data\n",
    "X_resampled = scaler.transform(X_resampled)\n",
    "# Train a linear regression model using the training set\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "# feature scaling - standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "# predictions\n",
    "y_test_pred = lr.predict(X_test)\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5677a0",
   "metadata": {},
   "source": [
    "Trying SelectKBest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cd7c39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After selecting best 3 features: (6112, 20)\n",
      "Selected best 20:\n",
      "Index(['max_planned_service_time', 'max_time_btw_stops', 'mean_time_btw_stops',\n",
      "       'median_time_btw_stops', 'ratio_delivery_time_stops',\n",
      "       'ratio_package_volume_planned_service',\n",
      "       'ratio_package_volume_violation_late_total_time',\n",
      "       'ratio_package_volume_violation_time',\n",
      "       'ratio_travel_time_packages_count', 'ratio_travel_time_stops',\n",
      "       'route_size', 'total_delivery_time', 'total_planned_service_time',\n",
      "       'travel_time', 'violation_avg_time', 'violation_early_avg_time',\n",
      "       'violation_early_total_time', 'violation_late_avg_time',\n",
      "       'violation_late_total_time', 'violation_total_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X = df.loc[:, df.columns.difference(['routeID', 'route_score', 'labels'])]\n",
    "y = df.loc[:, \"labels\"]\n",
    "\n",
    "select = SelectKBest(score_func=chi2, k=20)\n",
    "z = select.fit_transform(X, y)\n",
    "\n",
    "print(\"After selecting best 3 features:\", z.shape)\n",
    "filter = select.get_support()\n",
    "features = X.columns\n",
    "print(\"Selected best 20:\")\n",
    "print(features[filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd9725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
